# ğŸ¯ QUICK REFERENCE CARD

**Print this and keep it handy for your interview!**

---

## Project: Person Segmentation with U-Net

**Built:** November 2025 (1 week learning project)  
**Purpose:** Learn semantic segmentation for InnerGize ML internship  
**Tech:** PyTorch, U-Net, OpenCV, Albumentations

---

## âš¡ Key Numbers

| Metric | Value |
|--------|-------|
| **Architecture** | U-Net (encoder-decoder + skip connections) |
| **Parameters** | ~31 million |
| **Input Size** | 256Ã—256Ã—3 (RGB) |
| **Output Size** | 256Ã—256Ã—1 (binary mask) |
| **Encoder Blocks** | 4 (64â†’128â†’256â†’512 channels) |
| **Decoder Blocks** | 4 (512â†’256â†’128â†’64 channels) |
| **Skip Connections** | 4 (preserve spatial info) |

---

## ğŸ“Š Metrics I Implemented

### Dice Coefficient (F1 for Segmentation)
```
Formula: 2 Ã— |A âˆ© B| / (|A| + |B|)
Range: 0-1 (higher = better)
Use: Handles class imbalance well
```

### IoU (Intersection over Union)
```
Formula: |A âˆ© B| / |A âˆª B|
Range: 0-1 (higher = better)
Use: Stricter than Dice, standard metric
```

### Combined Loss
```
Loss = Î± Ã— BCE + (1-Î±) Ã— Dice Loss
Why: BCE for pixel-level, Dice for global structure
```

---

## ğŸ—ï¸ Architecture Flow

```
Input (3, 256, 256)
    â†“
[Conv-BN-ReLU] Ã— 2 â†’ 64 channels  â†â”€â”€â”
    â†“ MaxPool                          â”‚
[Conv-BN-ReLU] Ã— 2 â†’ 128 channels â†â”€â” â”‚
    â†“ MaxPool                         â”‚ â”‚
[Conv-BN-ReLU] Ã— 2 â†’ 256 channels â†â”â”‚ â”‚
    â†“ MaxPool                        â”‚â”‚ â”‚
[Conv-BN-ReLU] Ã— 2 â†’ 512 channels â†â”¤â”‚ â”‚
    â†“ MaxPool                       â”‚â”‚ â”‚
[Conv-BN-ReLU] Ã— 2 â†’ 512 (bottleneck)â”‚ â”‚
    â†“ Upsample                      â”‚â”‚ â”‚
[Concat + Conv] â†’ 256 channels â”€â”€â”€â”€â”€â”˜â”‚ â”‚
    â†“ Upsample                        â”‚ â”‚
[Concat + Conv] â†’ 128 channels â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â†“ Upsample                          â”‚
[Concat + Conv] â†’ 64 channels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ Upsample
[1Ã—1 Conv] â†’ 1 channel
    â†“
Output (1, 256, 256)
```

**Key:** Skip connections (â†’) combine encoder features with decoder

---

## ğŸ“ Quick Answers

### "What is U-Net?"
> Encoder-decoder architecture with skip connections. Encoder captures context 
> via downsampling, decoder enables precise localization via upsampling. Skip 
> connections preserve spatial details lost during downsampling.

### "Why U-Net for segmentation?"
> Skip connections are crucial - they combine high-resolution features from 
> encoder with semantic features from decoder. Originally designed for medical 
> imaging with limited data. Industry standard for segmentation.

### "Dice vs IoU?"
> Both measure overlap. Dice = 2Ã—intersection/(sum of sets), IoU = intersection/union. 
> Dice is more forgiving with class imbalance (2Ã— in numerator). IoU is stricter. 
> Medical imaging often uses Dice; computer vision often uses IoU. I implemented both.

### "How did you handle overfitting?"
> Multiple strategies: (1) Heavy data augmentation (flip, rotate, color jitter), 
> (2) Batch normalization for stability, (3) Weight decay (L2 regularization), 
> (4) Train/val split for monitoring, (5) Save best model only.

### "What's your training pipeline?"
> (1) Load images + masks with augmentation, (2) Forward pass through U-Net, 
> (3) Calculate combined loss (BCE + Dice), (4) Backprop + optimizer step, 
> (5) Validate on held-out data, (6) Track metrics, (7) Save best model.

---

## ğŸ’» Code Highlights

### Model Creation
```python
from models import UNet
model = UNet(n_channels=3, n_classes=1, bilinear=True)
# ~31M parameters
```

### Training
```python
from utils import CombinedLoss, evaluate_metrics
criterion = CombinedLoss(alpha=0.5)  # BCE + Dice
optimizer = Adam(model.parameters(), lr=0.001)
```

### Metrics
```python
from utils import dice_coefficient, iou_score
dice = dice_coefficient(predictions, targets)
iou = iou_score(predictions, targets)
```

---

## ğŸ”§ Data Augmentation (Albumentations)

- **Geometric:** Horizontal flip (50%), Rotation Â±15Â° (50%)
- **Color:** Brightness/contrast Â±20% (50%)
- **Blur:** Gaussian blur (30%)
- **Normalization:** ImageNet stats (mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])

**Why:** Increases dataset diversity, prevents overfitting, makes model robust

---

## ğŸ“ Project Structure (Quick)

```
models/unet.py          - U-Net implementation
utils/metrics.py        - Dice, IoU, losses
utils/dataset.py        - Data loading + augmentation
utils/visualization.py  - Plotting tools
train.py                - Training pipeline
inference.py            - Inference script
```

---

## ğŸ¯ Relevance to InnerGize

| Requirement | My Experience |
|-------------|---------------|
| Segmentation models | âœ… U-Net implemented from scratch |
| PyTorch/TensorFlow | âœ… PyTorch training pipeline |
| Dice, IoU metrics | âœ… Both implemented and understood |
| Computer vision | âœ… OpenCV, image preprocessing |
| Medical imaging | âœ… Rapid-test-analyzer + this project |
| Data augmentation | âœ… Albumentations pipeline |

---

## ğŸ’¡ What I Learned (1 Week)

âœ… Implemented CNN architecture from scratch  
âœ… Understanding of encoder-decoder patterns  
âœ… Skip connections and why they matter  
âœ… Loss function design for segmentation  
âœ… Evaluation metrics (Dice, IoU)  
âœ… PyTorch training loops  
âœ… Data augmentation strategies  
âœ… Medical imaging workflows  

---

## ğŸ—£ï¸ Key Phrases to Use

âœ… "I built this last week specifically to learn segmentation"  
âœ… "Skip connections preserve spatial information during upsampling"  
âœ… "Dice coefficient handles class imbalance better than BCE alone"  
âœ… "The architecture has ~31M parameters with 4 encoder-decoder stages"  
âœ… "I can explain every component because I implemented it myself"  
âœ… "These skills directly transfer to ear placement region detection"  

---

## âš ï¸ Don't Say

âŒ "I've been doing segmentation for years"  
âŒ "I'm an expert in deep learning"  
âŒ Anything you can't back up with code  
âŒ Memorized definitions without understanding  

---

## ğŸ¯ Interview Strategy

1. **Be Honest:** "Built this last week to learn for this role"
2. **Show Understanding:** Explain architecture, not just memorize
3. **Demonstrate Code:** Offer to walk through implementation
4. **Connect Dots:** "Skills transfer to your ear detection problem"
5. **Show Enthusiasm:** "Excited to learn more under mentorship"

---

## ğŸ“ Emergency Reminders

- **U-Net author:** Ronneberger et al., 2015
- **Originally for:** Biomedical image segmentation
- **Key innovation:** Skip connections
- **My implementation:** PyTorch, 1,500 lines, 1 week
- **Can demo:** Training, inference, metrics
- **Combined with:** Rapid-test-analyzer (medical imaging)

---

## ğŸš€ Confidence Boosters

You have:
âœ… Working code (can run live demo)
âœ… Real understanding (built it yourself)
âœ… Relevant skills (exactly what they need)
âœ… Initiative (proactive learning)
âœ… Medical context (rapid-test-analyzer)
âœ… Honesty (transparent about timeline)

You are a **strong candidate** for an ML internship!

---

**Print this card. Keep it during interview. You've got this! ğŸ’ª**

---

*Quick Commands:*
```bash
# Train
python train.py --epochs 50 --batch-size 8

# Inference
python inference.py --image test.jpg --visualize

# Test
python test_setup.py
```
